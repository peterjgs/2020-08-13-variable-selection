---
title: "Variable selection"
author: "Peter Geelan-Small, Stats Central, UNSW"
date: "13/08/2020"
output:
  ioslides_presentation:
    logo: StatsCentralLogo_ioslides.png
    css: ioslide_styles.css
---    


<style type="text/css">
body p {
  color: #000000;

ul { 
  display: block;
  color: #000000;
}

ol { 
  display: block;
  color: #000000;
}

</style>



<style>
div.footnotes {
  position: absolute;
  bottom: 0;
  margin-bottom: 10px;
  width: 80%;
  font-size: 0.6em;
  color: #000000;
}
</style>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

<script>
  $(document).ready(function() {
    $('slide:not(.backdrop):not(.title-slide)').append('<div class=\"footnotes\">');

    $('footnote').each(function(index) {
      var text  = $(this).html();
      var fnNum = (index+1).toString().sup();
      $(this).html(text + fnNum);

      var footnote   = fnNum + ': ' + $(this).attr('content') + '<br/>';
      var oldContent = $(this).parents('slide').children('div.footnotes').html();
      var newContent = oldContent + footnote;
      $(this).parents('slide').children('div.footnotes').html(newContent);
    });
  });
</script>



```{r setup, include = F}

library(knitr)

knitr::opts_chunk$set(echo = F, warning = F, message = F, 
                      fig.align = "center", fig.path = "figs/")

##  Need this so tables are formatted nicely
options("kableExtra.html.bsTable" = T)

```


```{r message = F}

library(ISwR)
library(RcmdrMisc)
library(ggplot2)
library(tidyverse)
library(GGally)
library(car)
library(glmnet)
library(leaps)

```


## Statistical inference - main types of inference

- Parameter estimation - finding a plausible range of values for a parameter of interest  - e.g. coefficient of a particular predictor

- Hypothesis testing - looking at the effect of a focal predictor - testing if the coefficient of the predictor is zero

- Predicting future values of the response from predictors

- Finding which predictors are associated with the response - _active_ predictors versus _inactive_ predictors


A good predictive model aids parameter estimation and hypothesis testing

Variable selection is a type of inference - one of many methods in general area of model selection


##  Example: Respiratory muscle strength in cystic fibrosis

Measurements of a number of clinical variables were taken on 25 patients with cystic fibrosis aged from 7 to 23 years. The response variable is maximum expiratory pressure (`pemax`).<footnote content = "Dalgaard 2008, Introductory Statistics with R, Springer; O’Neill et al. 1983,  Am. Rev. Respir. Dis., 128:1051–1054."></footnote>

- What variables are associated with (active predictors of) `pemax`?

- What is a useful prediction model for `pemax`?

<br>

_Response_ 

- `pemax`: maximum expiratory pressure



##  Example: Cystic fibrosis

- `age`: age (yr)
- `sex`:  coded 0: male, 1:female
- `height`: height (cm)
- `weight`: weight (kg)
- `bmp`: body mass pc. (% of normal) - indicator of malnutrition

_Lung function indicators_

- `fev1`: forced expiratory volume
- `rv`:  residual volume
- `frc`: functional residual capacity
- `tlc`: total lung capacity


<div class="notes">

Note: BMP = Wt/(Ht)^2 as percentage of age-specific median for normal individuals

</div>

##  Example: Cystic fibrosis - variables

```{r}

data(cystfibr)
str(cystfibr)

```


##  Example: Cystic fibrosis - all pairs plot

```{r}

pairs(cystfibr, gap = 0)

```


##  Example: Cystic fibrosis - summary statistics


```{r}

numSummary(cystfibr, 
           statistics = c("mean", "sd", "median", "quantiles", "IQR"),
           quantiles = c(0.5))

```

##  Example: Cystic fibrosis - correlations


```{r}

round(cor(cystfibr), digits = 2)

```


##  Example: Cystic fibrosis - regression model

Model: multivariable linear regression 


```{r results = "hide"}

cfib.lm1 <- lm(pemax ~ ., data = cystfibr)

summary(cfib.lm1)

```


```{r}

round(summary(cfib.lm1)$coef, digits = 4)

f_obs <- summary(cfib.lm1)$fstat

adjR2 <- round(summary(cfib.lm1)$adj.r.squared, digits = 4)

p_global <- round(1 - pf(f_obs[1], f_obs[2], f_obs[3]), digits = 4)

print(paste("Adjusted R-sq =", adjR2, "      p value =", p_global),
      quote = F)

```

##  Example: Cystic fibrosis - collinearity


Global P value small, no P values for model coefficients small?

Correlations among variables are interfering with estimated standard errors - _collinearity_

Check via _variance inflation factor_

```{r}

round(vif(cfib.lm1), digits = 3)

```


Values of VIF > 10 show concerning collinearity

VIF values show why individual P values are not smaller


##  Example: Cystic fibrosis - model assumptions

Check model assumptions

```{r}

par(mfrow = c(1, 2))
plot(rstandard(cfib.lm1) ~ fitted(cfib.lm1))
abline(h = 0, lty = 2)
qqPlot(residuals(cfib.lm1))
par(mfrow = c(1, 1))

```



## Variable selection - criteria and methods

Criteria applied to a model (well or not!) for deciding the fate of a variable:

- P value derived from some statistic ($t$, $\;F$, $\;\chi^2$)

- Measure of model fit - mean squared error (residual mean square), adjusted $R^2$

- Information criterion - AIC, BIC (combination of measure of model fit and penalty for larger model)


For these criteria, smaller is better, except for adjusted $R^2$, where larger is better


## Variable selection - criteria and methods


**Methods**

- Stepwise methods - forwards, backwards, both (1960)
  - one variable added or removed at each step

- Validation methods
  - measure how well models predict using new data (1990s)
  - randomly split data set into training and test sets
  - all subsets combined with k-fold cross-validation

- Penalised estimation methods - model coefficient estimates forced towards zero
  - penalty term is based on magnitude of model coefficients
  - LASSO (1996)


## Variable selection - criteria and methods

Consensus view is use expert knowledge first to _simplify_ your model

- eliminate unnecessary predictors


Stepwise methods - can be useful but strongly criticised by some

- no statistical justification but if you must ...
- do not use P values for decisions 
  - hypothesis testing not appropriate for model selection as no a priori hypothesis is tested 
  - multiple testing problems
- use information criterion (AIC, BIC)



## Variable selection - criteria and methods

Validation methods

- common criterion is mean squared error
- good for comparing predictive capability of models and so variable selection
- choose appropriate "k" for k-fold cross-validation - one recommendation:
  - leave-one-out (i.e. N-fold c.v.) if n < 20
  - 10-fold c.v. for 20<n<100
  - 5-fold c.v. for n>100


Penalised estimation methods (e.g. LASSO)

- main goal is predictive capability of model
- good when many parameters or small sample


## Variable selection - criteria and methods

Each method also has its _limitations_ and _disadvantages_

- Stepwise methods 
  - can be undermined by collinearity
  - validity of multiple steps is questionable
- AIC and BIC rely on model being close to correct
- Cross-validation requires only independent splits for training and test data but different results for different "k"
- LASSO estimates are biased and no standard errors are available




##  Example: Cystic fibrosis - active predictors

- What variables are associated with (active predictors of) `pemax`?

LASSO

```{r}

X <-
  cystfibr %>%
  select(-pemax)

X <- as.matrix(X)

cfib.cv <- cv.glmnet(X, cystfibr$pemax)

plot(cfib.cv)

```

##  Example: Cystic fibrosis - active predictors

```{r}

cfib.las <- glmnet(X, cystfibr$pemax, lambda = cfib.cv$lambda.min)

cfib.las$beta

```

Available output:

- active predictors and model coefficients
- no P values
- no standard errors



##  Example: Cystic fibrosis - prediction model

- What is a useful prediction model for `pemax`?

k-fold cross-validation (k = 1, leave-one-out) with all subsets in each fold


```{r}

##  Function to get predicted values
##  See James et al., p. 249

predict.regsubsets <- function(object, newdata, id,...){
  form <- as.formula(object$call[[2]])
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  mat[ , xvars]%*%coefi
}

```



```{r}

##  Set no. of folds, k

k <- 25

#RNGversion(vstr = "4.0.2")
#set.seed(1)

######
######  Run one of the next two lines of code only
######

##  Next line for leave-one-out cross validation
folds <- sample(1:k, nrow(cystfibr), replace = F)

##  Next line for k-fold cross validation
#folds <- sample(1:k, nrow(cystfibr), replace = T)


#folds

table(folds)

cv.errors <- matrix(NA , nrow = k, ncol = 9, 
                    dimnames = list(NULL, paste(1:9)))

for(j in 1:k){
  best.fit <- regsubsets(pemax ~ ., data = cystfibr[folds != j, ], 
                         nvmax = 9)
  #print(coef(best.fit, 3))
  for(i in 1:9){
    pred <- predict(best.fit, cystfibr[folds == j, ], id = i)
    cv.errors[j,  i] = mean((cystfibr$pemax[folds == j] - pred)^2)
  }
}

```



```{r}

mean.cv.errors <- apply(cv.errors, 2, mean, na.rm = T)

mean.cv.errors

```

```{r}

print(paste("No. of predictors in final model =", which.min(mean.cv.errors)), quote = F)

```


##  Example: Cystic fibrosis - prediction model


```{r}

plot(mean.cv.errors, type = "b")

```


##  Example: Cystic fibrosis - prediction model


```{r}

reg.best <- regsubsets(pemax ~ ., data = cystfibr, nvmax = 9)

reg.best.ind <- which.min(mean.cv.errors)

coef(reg.best, reg.best.ind)

```


Look at terms in 4-predictor model from c.v. runs

```{r}

coef(reg.best, 4)

```


Strange:

- both weight and bmp are in model when cor(weight, bmp) = 0.67

- coef of bmp is negative when cor(pemax, bmp) = 0.23

Possible overfitting?


<div class="notes">

Note: BMP = Wt/(Ht)^2 as percentage of age-specific median for normal individuals

cor(weight, bmp) = 0.67

cor(pemax, bmp) = 0.23

Strange both weight and bmp are in model and that coef of bmp is negative (despite weak +ve correlation between pemax and bmp)

</div>


##  Example: Cystic fibrosis - prediction model

Optimal model from cross-validation with all subsets fitted on full data set

```{r}

cfib.lm.cv3 <- lm(pemax ~ weight + bmp + fev1, data = cystfibr)

round(summary(cfib.lm.cv3)$coef, digits = 4)

f_obs <- summary(cfib.lm.cv3)$fstat

adjR2 <- round(summary(cfib.lm.cv3)$adj.r.squared, digits = 4)

p_global <- round(1 - pf(f_obs[1], f_obs[2], f_obs[3]), digits = 4)

print(paste("Adjusted R-sq =", adjR2, "      p value =", p_global),
      quote = F)

```


##  Example: Cystic fibrosis - prediction model

For prediction models:

- some overfitting is not a problem

- some collinearity is not a problem


##  Example: Cystic fibrosis - active predictors

Simplify the model

- use logic from expert knowledge - consider groups of predictors

Lung function: `fev1`, `rv`, `frc`, `tlc`

Remove these other lung function indicators as a group

Model comparison criteria:

- AIC - overfits, better for prediction model

- BIC - penalises larger models harder, good for active predictors

- As models are _nested_, can use an $F$ test (see note at end of slides)



##  Example: Cystic fibrosis - active predictors

Simplify the model contd

```{r}

cfib.lm.noLung <- update(cfib.lm1, . ~ . - fev1 - rv - frc - tlc)

AIC_f <- round(AIC(cfib.lm1), digits = 2)

AIC_r <- round(AIC(cfib.lm.noLung), digits = 2)

print(paste("AIC full model:", AIC_f), quote = F)

print(paste("AIC reduced model:", AIC_r), quote = F)

print(paste("AIC_full - AIC_red =", round(AIC_f - AIC_r, digits = 2)), 
      quote = F)

```


```{r}

cfib.lm.noLung <- update(cfib.lm1, . ~ . - fev1 - rv - frc - tlc)

BIC_f <- round(BIC(cfib.lm1), digits = 2)

BIC_r <- round(BIC(cfib.lm.noLung), digits = 2)

print(paste("BIC full model:", BIC_f), quote = F)

print(paste("BIC reduced model:", BIC_r), quote = F)

print(paste("BIC_full - BIC_red =", round(BIC_f - BIC_r, digits = 2)), 
      quote = F)

```

Model without lung function variables appears better


##  Example: Cystic fibrosis - active predictors

Simplify the model contd


$F$ test for nested models

```{r}

anova(cfib.lm.noLung, cfib.lm1, test = "F")

```

Smaller model is no worse than larger model


##  Example: Cystic fibrosis - active predictors


```{r}

round(summary(cfib.lm.noLung)$coef, digits = 4)

f_obs <- summary(cfib.lm.noLung)$fstat

adjR2 <- round(summary(cfib.lm.noLung)$adj.r.squared, digits = 4)

p_global <- round(1 - pf(f_obs[1], f_obs[2], f_obs[3]), digits = 4)

print(paste("Adjusted R-sq =", adjR2, "      p value =", p_global),
      quote = F)

```

Collinearity still present - possibly obscuring relationships

```{r}

vif(cfib.lm.noLung)

```


##  Example: Cystic fibrosis - active predictors

Simplify the model contd

Remove `age`

```{r}

cfib.lm.noLung2 <- update(cfib.lm.noLung, . ~ . - age)

round(summary(cfib.lm.noLung2)$coef, digits = 4)

f_obs <- summary(cfib.lm.noLung2)$fstat

adjR2 <- round(summary(cfib.lm.noLung2)$adj.r.squared, digits = 4)

p_global <- round(1 - pf(f_obs[1], f_obs[2], f_obs[3]), digits = 4)

print(paste("Adjusted R-sq =", adjR2, "      p value =", p_global),
      quote = F)

```

Collinearity still present

```{r}

vif(cfib.lm.noLung2)

```


##  Example: Cystic fibrosis - active predictors

- Perhaps no neat ending here in specifying active predictors

  - cor(height, weight) = 0.92 so possibly one should have been removed at the start

- Different methods may lead to different results



## Inference after model selection - Caveats

- Full fitted model is only model giving accurate standard errors and P values

- Data-driven model selection, esp. stepwise methods, produce estimated standard errors of coefficients and P values that are too small<footnote content = "Harrell 2015, Regression Modeling Strategies, Springer, 2nd ed., s. 4.3"></footnote> 

- Most parsimonious model may not give best parameter estimates or predictions<footnote content = "Leeb & P&ouml;tscher 2005 https://doi.org/10.1017/S0266466605050036"></footnote>





##  Variable selection - Recommendations

- In study design, use expert knowledge to list predictors (do not use the data later to "help"!)

- Plan to collect adequate data on all variables

- Pre-specify a small number of candidate models

- Avoid including too many predictors for your sample size


##  Variable selection - Recommendations contd

- If variable selection is necessary:

  - use penalised or resampling methods or

  - if you must use stepwise methods

    - use a limited, structured approach (e.g. consider groups of predictor variables)
  
    - use _minimal_ backwards elimination steps if you want parsimony (active predictors) rather than accuracy (good predictions)

    - validate the model using a resampling method or external test data<footnote content = "Harrell 2015, Regression Modeling Strategies, Springer, 2nd ed., s. 4.12"></footnote>
  
##  Variable selection - Recommendations contd

  
- What is the role of modelling in your field?  

  - systems biology - complex problems addressed by computational modelling and simulation<footnote content = "Macleod 2018 https://doi.org/10.1007/s40656-017-0183-9"></footnote>
  
  - business - big data - Netflix Prize (100 million records)<footnote content = "Hastie 2015 Statistical learning with big data https://web.stanford.edu/~hastie/TALKS/SLBD_new.pdf"></footnote>
  
  - clinical science and health - diagnostic and prognostic inferences ... for care decisions ... policy<footnote content = "Henley 2020 https://doi.org/10.1080/24709360.2019.1618653"></footnote>
  
  - more generally - how statistical modelling decisions connect with answering scientific questions<footnote content = "Navarro 2019 https://doi.org/10.1007/s42113-018-0019-z"></footnote>
  
  

##  Variable selection - future seminar topics?

Many issues not raised:

- how many variables is it feasible to start with in a model?

- after you've done model selection, how much can you trust P values for model parameter estimates?

- what methods can be used for models with multiple categorical predictor variables?

- what about mixed models with fixed and random effects - i.e. where the data records are not independent, such as observations made on subjects in different groups?

- what methods can be used with other types of model - e.g. non-linear models or where response variable is binary, small count, categorical, ...?



##  Useful resources

**Books**

Dalgaard P 2008. _Introductory Statistics with R._ Springer, 2nd ed. (Contains description of example data set and analysis notes - UNSW Library e-book)

Harrell F 2015. _Regression Modeling Strategies,_ Springer, 2nd ed.

James G et al. 2013. _An Introduction to Statistical Learning - with Applications in R._ Springer. https://doi.org/10.1007/978-1-4614-7138-7 **Extremely useful** (Free download available here: http://faculty.marshall.usc.edu/gareth-james/ISL/)


##  Useful resources

**Journal articles**

Heinze G & Dunkler D 2017. Five myths about variable selection. _Transplant International,_ 30(1), 6–10. https://doi.org/10.1111/tri.12895

Heinze G et al. 2018. Variable selection – A review and recommendations for the practicing statistician. _Biometrical Journal,_ 60(3), 431–449. https://doi.org/10.1002/bimj.201700067

Henley S et al. 2020. Statistical modeling methods: challenges and strategies. _Biostatistics and Epidemiology,_ 4(1), 105–139. https://doi.org/10.1080/24709360.2019.1618653

Krzywinski M & Altman N 2015. Points of Significance: Multiple Linear Regression, _Nature Methods_ 12(12): 1103-1104. https://doi.org/10.1038/nmeth.3665


##  Useful resources

**Journal articles**

Leeb H & P&ouml;tscher B M 2005. Model selection and inference: facts and fiction. _Econometric Theory_ 21(1), 21-59. https://doi.org/10.1017/S0266466605050036

Sauerbrei W et al. 2020. State of the art in selection of variables and functional forms in multivariable analysis—outstanding issues. _Diagnostic and Prognostic Research,_ 4(1). https://doi.org/10.1186/s41512-020-00074-3


## Note on $F$ test

To test whether _one_ parameter in our regression model is zero, we can use a $t$ test because a $t$ test can handle one parameter at a time. The $t$ test for whether the coefficient of `fev1` is zero, given all the other terms remain in the model, gives a $P$ value of 0.33 (see slide 9).

If, however, we want to test whether the coefficients of a group of parameters are _all_ zero, we cannot use a $t$ test, which can handle only one parameter at a time, but we can use an $F$ test, if the model without that group of parameters is nested within the larger model. It's called an $F$ test because the test statistic is an $F$ statistic.

(continued over)

## Note on $F$ test contd

To test if the coefficients of `fev1`, `rv`, `frc` and `tlc` are _all_ zero, we can use an $F$ test to compare the model without those four predictors against the model with all the nine predictors because (1) the two models are nested and (2) we are testing more than one parameter at the same time (see slide 26).

See Quinn G & Keough M 2002. _Experimental Design and Data Analysis for Biologists,_ Cambridge University Press, sect. 6.1.4 (UNSW Library e-book)

Note that if we were using a different type of model not fitted by least squares, we might need to use a different test, appropriate for that type of model, to answer this type of question.